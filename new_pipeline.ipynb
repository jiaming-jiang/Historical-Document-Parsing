{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyMuPDF in c:\\programdata\\anaconda3\\envs\\ada\\lib\\site-packages (1.24.13)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyMuPDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from io import BytesIO\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685860f0",
   "metadata": {},
   "source": [
    "### Step 1: Run OCR, Get ocr_df, Concat ocr_df into text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_page_number(filename):\n",
    "    \"\"\"\n",
    "    Extract numeric page number from filename like 'page_001.png'\n",
    "    \"\"\"\n",
    "    match = re.search(r'page[_\\-]?(\\d+)', filename, re.IGNORECASE)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "def images_to_ocr_df(folder_path):\n",
    "    \"\"\"\n",
    "    Run OCR with bbox info on all images in a folder, using filename-based page numbers.\n",
    "    \"\"\"\n",
    "    ocr_dfs = []\n",
    "    image_files = sorted([\n",
    "        f for f in os.listdir(folder_path) \n",
    "        if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "    ])\n",
    "\n",
    "    for filename in image_files:\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "        page_num = extract_page_number(filename)\n",
    "\n",
    "        img = Image.open(image_path)\n",
    "        df = pytesseract.image_to_data(img, output_type=pytesseract.Output.DATAFRAME)\n",
    "        df = df[df.text.notnull()]\n",
    "        df[\"text\"] = df[\"text\"].astype(str)\n",
    "        df[\"page_num\"] = page_num if page_num is not None else -1  # fallback\n",
    "\n",
    "        ocr_dfs.append(df)\n",
    "\n",
    "    ocr_df = pd.concat(ocr_dfs, ignore_index=True)\n",
    "    return ocr_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_df = images_to_ocr_df(\"BW_12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>page_num</th>\n",
       "      <th>block_num</th>\n",
       "      <th>par_num</th>\n",
       "      <th>line_num</th>\n",
       "      <th>word_num</th>\n",
       "      <th>left</th>\n",
       "      <th>top</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>conf</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>62</td>\n",
       "      <td>215</td>\n",
       "      <td>26</td>\n",
       "      <td>92.216522</td>\n",
       "      <td>Osterreichische</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>92</td>\n",
       "      <td>43</td>\n",
       "      <td>73</td>\n",
       "      <td>5.081444</td>\n",
       "      <td>[)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>92</td>\n",
       "      <td>263</td>\n",
       "      <td>35</td>\n",
       "      <td>91.264214</td>\n",
       "      <td>Nationalbibliothek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>888</td>\n",
       "      <td>100</td>\n",
       "      <td>111</td>\n",
       "      <td>22</td>\n",
       "      <td>89.556755</td>\n",
       "      <td>digitalisiert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1007</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "      <td>97.001877</td>\n",
       "      <td>mit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101861</th>\n",
       "      <td>5</td>\n",
       "      <td>475</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>415</td>\n",
       "      <td>759</td>\n",
       "      <td>35</td>\n",
       "      <td>62</td>\n",
       "      <td>37.457565</td>\n",
       "      <td>Lore.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101862</th>\n",
       "      <td>5</td>\n",
       "      <td>475</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>425</td>\n",
       "      <td>848</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>‘:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101863</th>\n",
       "      <td>5</td>\n",
       "      <td>475</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1069</td>\n",
       "      <td>1409</td>\n",
       "      <td>95.000000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101864</th>\n",
       "      <td>5</td>\n",
       "      <td>476</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1020</td>\n",
       "      <td>276</td>\n",
       "      <td>116</td>\n",
       "      <td>228</td>\n",
       "      <td>95.000000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101865</th>\n",
       "      <td>5</td>\n",
       "      <td>477</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1229</td>\n",
       "      <td>1518</td>\n",
       "      <td>95.000000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101866 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        level  page_num  block_num  par_num  line_num  word_num  left  top  \\\n",
       "0           5         1          1        1         1         1   130   62   \n",
       "1           5         1          1        1         2         1    76   92   \n",
       "2           5         1          1        1         2         2   130   92   \n",
       "3           5         1          1        1         2         3   888  100   \n",
       "4           5         1          1        1         2         4  1007  100   \n",
       "...       ...       ...        ...      ...       ...       ...   ...  ...   \n",
       "101861      5       475          1        1         3         1   415  759   \n",
       "101862      5       475          1        1         3         2   425  848   \n",
       "101863      5       475          2        1         1         1     0    0   \n",
       "101864      5       476          1        1         1         1  1020  276   \n",
       "101865      5       477          1        1         1         1     0    0   \n",
       "\n",
       "        width  height       conf                text  \n",
       "0         215      26  92.216522     Osterreichische  \n",
       "1          43      73   5.081444                  [)  \n",
       "2         263      35  91.264214  Nationalbibliothek  \n",
       "3         111      22  89.556755       digitalisiert  \n",
       "4          30      17  97.001877                 mit  \n",
       "...       ...     ...        ...                 ...  \n",
       "101861     35      62  37.457565               Lore.  \n",
       "101862     24       7   0.000000                  ‘:  \n",
       "101863   1069    1409  95.000000                      \n",
       "101864    116     228  95.000000                      \n",
       "101865   1229    1518  95.000000                      \n",
       "\n",
       "[101866 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\ada\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "def ocr_df_to_text_simple(ocr_df, correct_brevet=True):\n",
    "    \"\"\"\n",
    "    Simply concatenate OCR results into plain text per page (without layout or visual structure).\n",
    "    \n",
    "    Parameters:\n",
    "        ocr_df (pd.DataFrame): The DataFrame returned from pytesseract.image_to_data(),\n",
    "                               containing word-level OCR results with columns like 'text', 'page_num', etc.\n",
    "        correct_brevet (bool): If True, apply fuzzy matching to correct words that resemble 'BREVET'.\n",
    "\n",
    "    Returns:\n",
    "        str: A long string simulating the original OCR text, organized by page and ready for regex parsing.\n",
    "    \"\"\"\n",
    "    pages = []\n",
    "\n",
    "    # Iterate through each page number in order\n",
    "    for page in sorted(ocr_df.page_num.unique()):\n",
    "        # Select rows for the current page\n",
    "        page_df = ocr_df[ocr_df.page_num == page]\n",
    "        words = []\n",
    "\n",
    "        # Loop through words on the page\n",
    "        for word in page_df[\"text\"]:\n",
    "            # If fuzzy correction is enabled and word is close to 'BREVET', replace it\n",
    "            if correct_brevet and fuzz.ratio(word.upper(), \"BREVET\") >= 70:\n",
    "                words.append(\"BREVET\")\n",
    "            else:\n",
    "                words.append(word)\n",
    "\n",
    "        # Combine all words into a single line of text for the page, with a page header\n",
    "        page_text = f\"=== Extracted Text from page_{page}.png ===\\n\" + \" \".join(words)\n",
    "        pages.append(page_text)\n",
    "\n",
    "    # Join all pages with double line breaks between them\n",
    "    return \"\\n\\n\".join(pages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_text = ocr_df_to_text_simple(ocr_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Regex matching and metadata extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def extract_patent_data(text):\n",
    "    pattern = (\n",
    "        r\"[\\s/\\\\_\\-]*BREVET\\s+(?:D[’'`]?|DE)\\s*(?P<category>\\w+)\\s+DE\\s+(?P<duration>\\w+)\\s+ANS[,\\\\s]*\\n?\"\n",
    "        r\"(?P<content>.*?)(?=[\\s/\\\\_\\-]*BREVET|\\Z)\"\n",
    "    )\n",
    "    matches = re.finditer(pattern, text, flags=re.DOTALL | re.IGNORECASE)\n",
    "    results = []\n",
    "\n",
    "    for match in matches:\n",
    "        data = match.groupdict()\n",
    "        block_text = match.group(0)\n",
    "        data['block_text'] = block_text.strip()\n",
    "        data['word_count'] = len(block_text.split())\n",
    "        data['char_count'] = len(block_text)\n",
    "\n",
    "        # Title\n",
    "        title_match = re.search(r\"Pour\\s+(.+?)(?=\\n|,|Au sieur|Aux sieurs|À madame)\", block_text, re.IGNORECASE)\n",
    "        data['title'] = title_match.group(1).strip() if title_match else \"Unknown\"\n",
    "\n",
    "        # Patentee\n",
    "        patentee_match = re.search(r\"(?:Au sieur|Aux sieurs|À madame)\\s+([^.,\\n]+)\", block_text, re.IGNORECASE)\n",
    "        data['patentee'] = patentee_match.group(1).strip() if patentee_match else \"Unknown\"\n",
    "\n",
    "        # Page number\n",
    "        page_match = re.search(r\"=== Extracted Text from page_(\\d+)\", block_text)\n",
    "        data['page_num'] = int(page_match.group(1)) if page_match else -1\n",
    "\n",
    "        results.append(data)\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = extract_patent_data(ocr_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Enrich metadata using bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_block_with_bbox(row, ocr_df, top_margin=60, bottom_margin=120):\n",
    "    # Filter OCR data for the corresponding page\n",
    "    page_df = ocr_df[ocr_df.page_num == row['page_num']].copy()\n",
    "    page_df = page_df.sort_values(by='top')\n",
    "\n",
    "    # Locate the line containing the word 'BREVET'\n",
    "    brevet_idx = page_df[page_df.text.str.upper() == \"BREVET\"]\n",
    "    if brevet_idx.empty:\n",
    "        return row.to_dict()  # Keep original row if BREVET is not found\n",
    "\n",
    "    brevet_top = brevet_idx.iloc[0].top\n",
    "\n",
    "    # Search upward for a date line (typically above BREVET)\n",
    "    above = page_df[(page_df.top < brevet_top) & (page_df.top > brevet_top - top_margin)]\n",
    "    date = None\n",
    "    for line_top in sorted(above.top.unique(), reverse=True):\n",
    "        line_words = above[above.top == line_top].sort_values(by='left')\n",
    "        line_text = \" \".join(line_words.text.tolist())\n",
    "        if re.search(r\"\\b(18|19|20)\\d{2}\\b\", line_text):\n",
    "            date = line_text\n",
    "            break\n",
    "\n",
    "    # Search downward for title (Pour ...) and patentee (Au sieur, À madame, etc.)\n",
    "    below = page_df[(page_df.top > brevet_top) & (page_df.top < brevet_top + bottom_margin)]\n",
    "    title = None\n",
    "    patentee = None\n",
    "    for line_top in sorted(below.top.unique()):\n",
    "        line_words = below[below.top == line_top].sort_values(by='left')\n",
    "        line_text = \" \".join(line_words.text.tolist())\n",
    "\n",
    "        if not title and re.search(r\"\\bPour\\s\", line_text, re.IGNORECASE):\n",
    "            title = line_text\n",
    "\n",
    "        if not patentee and re.search(r\"(Au sieur|Aux sieurs|À madame)\", line_text, re.IGNORECASE):\n",
    "            patentee = line_text\n",
    "\n",
    "    # Return the enriched block, preserving original values if not found\n",
    "    return {\n",
    "        \"page_num\": row[\"page_num\"],\n",
    "        \"category\": row[\"category\"],\n",
    "        \"duration\": row[\"duration\"],\n",
    "        \"title\": title or row[\"title\"],\n",
    "        \"patentee\": patentee or row[\"patentee\"],\n",
    "        \"date\": date,\n",
    "        \"word_count\": row[\"word_count\"],\n",
    "        \"char_count\": row[\"char_count\"],\n",
    "        \"block_text\": row[\"block_text\"]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_blocks = [enrich_block_with_bbox(row, ocr_df) for _, row in df_raw.iterrows()]\n",
    "df_final = pd.DataFrame(enriched_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 title difference： 5\n",
      "🔍 patentee difference： 0\n",
      "🗓️  date difference： 1\n"
     ]
    }
   ],
   "source": [
    "print(\"🔍 title difference：\", (df_raw[\"title\"] != df_final[\"title\"]).sum())\n",
    "print(\"🔍 patentee difference：\", (df_raw[\"patentee\"] != df_final[\"patentee\"]).sum())\n",
    "print(\"🗓️  date difference：\", df_final[\"date\"].notna().sum())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
